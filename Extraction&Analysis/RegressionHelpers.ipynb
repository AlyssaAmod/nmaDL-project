{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RegressionHelpers.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMSDgsnSX6RCNbRNncItgbl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"cellView":"form","id":"qHIiXWZ7e7wy"},"source":["# @title Plotting Functions - CNN\n","\n","def show_stimulus(img, ax=None):\n","  \"\"\"Visualize a stimulus\"\"\"\n","  if ax is None:\n","    ax = plt.gca()\n","  ax.imshow(img, cmap=mpl.cm.binary)\n","  ax.set_aspect('auto')\n","  ax.set_xticks([])\n","  ax.set_yticks([])\n","  ax.spines['left'].set_visible(False)\n","  ax.spines['bottom'].set_visible(False)\n","\n","def plot_corr_matrix(rdm, ax=None):\n","  \"\"\"Plot dissimilarity matrix\n","\n","  Args:\n","    rdm (numpy array): n_stimuli x n_stimuli representational dissimilarity\n","      matrix\n","    ax (matplotlib axes): axes onto which to plot\n","\n","  Returns:\n","    nothing\n","\n","  \"\"\"\n","  if ax is None:\n","    ax = plt.gca()\n","  image = ax.imshow(rdm, vmin=0.0, vmax=2.0)\n","  ax.set_xticks([])\n","  ax.set_yticks([])\n","  cbar = plt.colorbar(image, ax=ax, label='dissimilarity')\n","\n","\n","def plot_multiple_rdm(rdm_dict):\n","  \"\"\"Draw multiple subplots for each RDM in rdm_dict.\"\"\"\n","  fig, axs = plt.subplots(1, len(rdm_dict),\n","                          figsize=(4 * len(resp_dict), 3.5))\n","\n","  # Compute RDM's for each set of responses and plot\n","  for i, (label, rdm) in enumerate(rdm_dict.items()):\n","\n","    image = plot_corr_matrix(rdm, axs[i])\n","    axs[i].set_title(label)\n","\n","\n","def plot_rdm_rdm_correlations(rdm_sim):\n","  \"\"\"Draw a bar plot showing between-RDM correlations.\"\"\"\n","  f, ax = plt.subplots()\n","  ax.bar(rdm_sim.keys(), rdm_sim.values())\n","  ax.set_xlabel('Deep network model layer')\n","  ax.set_ylabel('Correlation of model layer RDM\\nwith mouse V1 RDM')\n","\n","\n","def plot_rdm_rows(ori_list, rdm_dict, rdm_oris):\n","  \"\"\"Plot the dissimilarity of response to each stimulus with response to one\n","  specific stimulus\n","\n","  Args:\n","    ori_list (list of float): plot dissimilarity with response to stimulus with\n","      orientations closest to each value in this list\n","    rdm_dict (dict): RDM's from which to extract dissimilarities\n","    rdm_oris (np.ndarray): orientations corresponding to each row/column of RDMs\n","    in rdm_dict\n","\n","  \"\"\"\n","  n_col = len(ori_list)\n","  f, axs = plt.subplots(1, n_col, figsize=(4 * n_col, 4), sharey=True)\n","\n","  # Get index of orientation closest to ori_plot\n","  for ax, ori_plot in zip(axs, ori_list):\n","    iori = np.argmin(np.abs(rdm_oris - ori_plot))\n","\n","    # Plot dissimilarity curves in each RDM\n","    for label, rdm in rdm_dict.items():\n","      ax.plot(rdm_oris, rdm[iori, :], label=label)\n","\n","    # Draw vertical line at stimulus we are plotting dissimilarity w.r.t.\n","    ax.axvline(rdm_oris[iori], color=\".7\", zorder=-1)\n","\n","    # Label axes\n","    ax.set_title(f'Dissimilarity with response\\nto {ori_plot: .0f}$^o$ stimulus')\n","    ax.set_xlabel('Stimulus orientation ($^o$)')\n","\n","  axs[0].set_ylabel('Dissimilarity')\n","  axs[-1].legend(loc=\"upper left\", bbox_to_anchor=(1, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"uBmViF-WgM3x"},"source":["#@title Plotting Functions - Regression\n","def plot_weights(models, sharey=True):\n","  \"\"\"Draw a stem plot of weights for each model in models dict.\"\"\"\n","  n = len(models)\n","  f = plt.figure(figsize=(10, 2.5 * n))\n","  axs = f.subplots(n, sharex=True, sharey=sharey)\n","  axs = np.atleast_1d(axs)\n","\n","  for ax, (title, model) in zip(axs, models.items()):\n","\n","    ax.margins(x=.02)\n","    stem = ax.stem(model.coef_.squeeze(), use_line_collection=True)\n","    stem[0].set_marker(\".\")\n","    stem[0].set_color(\".2\")\n","    stem[1].set_linewidths(.5)\n","    stem[1].set_color(\".2\")\n","    stem[2].set_visible(False)\n","    ax.axhline(0, color=\"C3\", lw=3)\n","    ax.set(ylabel=\"Weight\", title=title)\n","  ax.set(xlabel=\"Neuron (a.k.a. feature)\")\n","  f.tight_layout()\n","\n","\n","def plot_function(f, name, var, points=(-10, 10)):\n","    \"\"\"Evaluate f() on linear space between points and plot.\n","\n","    Args:\n","      f (callable): function that maps scalar -> scalar\n","      name (string): Function name for axis labels\n","      var (string): Variable name for axis labels.\n","      points (tuple): Args for np.linspace to create eval grid.\n","    \"\"\"\n","    x = np.linspace(*points)\n","    ax = plt.figure().subplots()\n","    ax.plot(x, f(x))\n","    ax.set(\n","      xlabel=f'${var}$',\n","      ylabel=f'${name}({var})$'\n","    )\n","\n","\n","def plot_model_selection(C_values, accuracies):\n","  \"\"\"Plot the accuracy curve over log-spaced C values.\"\"\"\n","  ax = plt.figure().subplots()\n","  ax.set_xscale(\"log\")\n","  ax.plot(C_values, accuracies, marker=\"o\")\n","  best_C = C_values[np.argmax(accuracies)]\n","  ax.set(\n","      xticks=C_values,\n","      xlabel=\"$C$\",\n","      ylabel=\"Cross-validated accuracy\",\n","      title=f\"Best C: {best_C:1g} ({np.max(accuracies):.2%})\",\n","  )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qbvz0U5zftT1"},"source":["#@title Logistic regression functions\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score\n","\n","# Define the model\n","log_reg = LogisticRegression(penalty=\"none\")\n","\n","# Fit it to data\n","log_reg.fit(X, y)\n","\n","coefs_ = []\n","for c in cs:\n","    log_reg.set_params(C=c)\n","    log_reg.fit(X, y)\n","    coefs_.append(log_reg.coef_.ravel().copy())\n","\n","coefs_ = np.array(coefs_)\n","\n","def compute_accuracy(X, y, model):\n","  \"\"\"Compute accuracy of classifier predictions.\n","  Args:\n","    X (2D array): Data matrix\n","    y (1D array): Label vector\n","    model (sklearn estimator): Classifier with trained weights.\n","  Returns:\n","    accuracy (float): Proportion of correct predictions.\n","  \"\"\"\n","\n","  y_pred = model.predict(X)\n","\n","  accuracy = (y == y_pred).mean()\n","\n","  return accuracy\n","\n","\n","# Compute train accurcy\n","train_accuracy = compute_accuracy(X, y, log_reg)\n","print(f\"Accuracy on the training data: {train_accuracy:.2%}\")\n","\n","def model_selection(X, y, C_values):\n","  \"\"\"Compute CV accuracy for each C value.\n","  Args:\n","    X (2D array): Data matrix\n","    y (1D array): Label vector\n","    C_values (1D array): Array of hyperparameter values.\n","  Returns:\n","    accuracies (1D array): CV accuracy with each value of C.\n","  \"\"\"\n","  accuracies = []\n","  for C in C_values:\n","\n","    # Initialize and fit the model\n","    # (Hint, you may need to set max_iter)\n","    model = LogisticRegression(penalty=\"l2\", C=C, max_iter=5000)\n","\n","    # Get the accuracy for each test split using cross-validation\n","    accs = cross_val_score(model, X, y, cv=8)\n","\n","    # Store the average test accuracy for this value of C\n","    accuracies.append(accs.mean())\n","\n","  return accuracies\n","\n","\n","# Use log-spaced values for C\n","C_values = np.logspace(-4, 4, 9)\n","\n","# Compute accuracies\n","accuracies = model_selection(X, y, C_values)\n","\n","# Visualize\n","with plt.xkcd():\n","  plot_model_selection(C_values, accuracies)\n","\n","clf = LogisticRegression(\n","    C=50. / train_samples, penalty='l1', solver='saga', tol=0.1\n",")\n","clf.fit(X_train, y_train)\n","sparsity = np.mean(clf.coef_ == 0) * 100\n","score = clf.score(X_test, y_test)\n","# print('Best C % .4f' % clf.C_)\n","print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n","print(\"Test score with L1 penalty: %.4f\" % score)\n","\n","coef = clf.coef_.copy()\n","plt.figure(figsize=(10, 5))\n","scale = np.abs(coef).max()\n","for i in range(10):\n","    l1_plot = plt.subplot(2, 5, i + 1)\n","    l1_plot.imshow(coef[i].reshape(28, 28), interpolation='nearest',\n","                   cmap=plt.cm.RdBu, vmin=-scale, vmax=scale)\n","    l1_plot.set_xticks(())\n","    l1_plot.set_yticks(())\n","    l1_plot.set_xlabel('Class %i' % i)\n","plt.suptitle('Classification vector for...')\n","\n","run_time = time.time() - t0\n","print('Example run in %.3f s' % run_time)\n","plt.show()"],"execution_count":null,"outputs":[]}]}